Backend Implementation Steps

1) Repo scaffold
- backend/
  - app.py
  - core/{asr.py, features.py, prompt.py, music.py, mix.py}
  - models_cache/
  - requirements.txt
  - Dockerfile
- scripts/
  - smoke_backend.py
- deploy/
  - docker-compose.yml
  - nginx.conf

2) Requirements (pinned)
fastapi==0.115.0
uvicorn==0.30.6
torch==2.3.1
torchaudio==2.3.1
audiocraft==1.3.0
faster-whisper==1.0.3
librosa==0.10.1
soundfile==0.12.1
numpy==1.26.4
pydub==0.25.1
transformers==4.43.3
huggingface_hub==0.23.4
crepe==0.0.15
python-dotenv==1.0.1

3) Core functions
- load_models(): preload Whisper, MusicGen, CREPE, set device
- transcribe(audio): return transcript + segments
- extract_features(audio): energy, f0, speech rate, pauses
- decide_controls(features): mood, tempo, key, style_id
- build_prompt(controls): string
- generate_music(prompt, duration, seed, melody_ref?): WAV bytes
- mix_with_dialogue(dialogue_wav, bg_wav, bg_db=-18, ducking=0.3): apply sidechain ducking

4) Ducking algorithm
- Create speech activity mask from ASR segments.
- Attenuate background by ducking dB during speech windows with attack/release smoothing.
- Ensure no clipping; peak limit at -1 dBFS.

5) Performance
- Preload models on startup.
- Cache prompts->audio in memory LRU for quick regen.
- Limit duration to 90 s for demo.

6) Health and error handling
- /health checks GPU and model status.
- Return 413 for large files; 422 for unsupported format.
- Log stack traces.

7) Smoke test
- Generate 5 s tone as "dialogue" and ensure /compose returns WAV.